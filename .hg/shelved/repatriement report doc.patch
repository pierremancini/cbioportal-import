# HG changeset patch
# User shelve@localhost
# Date 1523005673 -7200
#      Fri Apr 06 11:07:53 2018 +0200
# Node ID 78f1f7b75ae5e1299622f19bfd9c9de249c44bf9
# Parent  b944863719de1549106f1b776f4852159c8b6522
changes to: Migration des scritps de transfert de fichier vers conteneur cbioportal.

diff --git a/README.md b/README.md
--- a/README.md
+++ b/README.md
@@ -1,24 +1,30 @@
 # Importer dans cBioportal
 
 
-## Utilisation de vcf2maf
+## build_study_data.py
 
-Avec la commande perl suivante on utilise vcf2maf qui utilise vep:
+Pour importer les fichiers .maf dans cBioportal il faut les organiser dans des dossiers spécifiques et les accompagner de fichiers de métadonnées.
 
+Voir la documentation offichielle: [cbioportal/File-Format](http://cbioportal.readthedocs.io/en/latest/File-Formats.html)
 
-Le conteneur de vcf2maf utilise un conteneur de vep.
+Le script build_study_data.py construit l'arborescence de fichiers d'importation i.e. le dossier contenant les study data.
 
+Donner en entrée, après l'argument --in-dir, le chemin du dossier contenant les fichiers .vcf à importer dans cBioportal.
 
-docker run -it --rm -v `volume_vep_path_local`:/root/.vep -v `volume_vcf2maf_path_local`:/data vcf2maf --input-vcf `input` --output-maf `output`
+Le script utilise le fichier de configuration build_config.yml. Le build_config.yml fournit par
+le dépot dans bitbucket est un exemple.
+
+
+### Conversion des .vcf en .maf
+
+Le script build_study_data.py utilise le conteneur de vcf2maf dans la fonction use_vcf2maf:
+
+```bash
+docker run -it --rm -v {} -v {} vcf2maf --input-vcf {} --output-maf {} --tumor-barcode-map {} -d --merge-maf
+```
 
 L'argument après le premier -v `volume_vep_path_local` correspond au chemin local du volume vep.
-
-Pour plus de détail sur les commandes du conteneur voir la documentation sur le dépot vcf2maf.
-
-
-Ce volume contient en cache les données de l'archive homo_sapiens_vep_86_GRCh37.tar.gz. Par defaut vep ira chercher les données dans ce volume.
-Néanmoins, si le cache il est possible de demander au conteneur vep de télécharger lui même les données.
-Il faut décommenter dans le Dockerfile (de vep) les lignes en dessous de la ligne "Download and unpack VEP's offline cache for GRCh37".
+Ce volume contient en cache les données de l'archive homo_sapiens_vep_91_GRCh37.tar.gz.
 
 L'argument après le deuxième -v `volume_vcf2maf_path_local` donne le dossier parent du dossier contenant les fichiers .vcf. Après utilisation de vcf2maf les fichiers .maf seront aussi dans ce volume.
 
@@ -26,38 +32,80 @@
 L'argument `output` donne le chemin dans le conteneur du dossier contenant les futurs .maf.
 
 
-Exemple de construction d'une commande vcf2maf en python:
+#### Update de la colone TUMOR_BARCODE des .maf
+
+Le script entrypoint.py de vcf2maf rempli les valeurs de la colone TUMOR_BARCODE en fonction des arguments --tumor-id ou --tumor-id-map.
+
+
+#### Fusion des .maf
+
+Le script entrypoint.py de vcf2maf possède une option --merge-maf qu'il faut utiliser pour l'importation dans cBioportal.
+
+
+## Commandes d'importation, suppression et rapport d'importation
+
+### Importation
+
+Une fois les study data contruites il faut mettre le dossier dans le volume du conteneur de cBioportal.
+
+Le conteneur cBioportal peut-être lancer sur k2so sur son noeud de virtualisation kvm01.
+
+Pour transferer le dossier study data sur le noeud de virtualisation on peut
+
+1) Utilisation de scp:
+
+Copie local -> scratch du noeud maitre de k2so
+```bash
+scp -r {study_dir_path} root@129.10.28.20:/scratch/pmancini/{study_name}
+```
+
+Aller sur le noeud maitre
+```bash
+ssh root@129.10.28.20
+```
+
+Copie joeud maitre -> noeud de virtualisation
+```bash
+cd /scratch/pmancini
+scp -r {study_name} root@kvm01:/data/dockerbuilds/cbioportal/studies/{study_name}
+```
+
+
+ou
+
+1')  utiliser le script python qui wrap l'utilisations des commandes de transfert:
 
 ```python
-cmd = "docker run -it --rm -v " + os.path.expanduser('~') + "/Code/mydockerbuild/vcf2maf/VEP_volume/cache/.vep:/root/.vep -v " + os.path.expanduser('~') + "/Code/mydockerbuild/vcf2maf/volume_data:/data vcf2maf --input-vcf " + os.path.join(os.sep, 'data', vcf_folder_name) + " -d --output-maf " + os.path.join(os.sep, 'data', 'temp_maf_dir')
+python3 transfer_study.py --study-path {}
 ```
 
-### Update de la colone TUMOR_BARCODE des .maf
+2) Commande dans le conteneur
 
-Le script entrypoint.py de vcf2maf rempli les valeurs de la colone TUMOR_BARCODE en fonction des arguments
---tumor-id ou --tumor-id-map.
+Lancement du conteneur:
+```bash
+docker exec -it cbioportal /bin/bash
+```
 
+Lancement du script d'importation de l'instance cBioportal:
+```bash
+cd /
+./cbioportal/core/src/main/scripts/importer/metaImport.py -s /cbio_studies/{study_name}/ -o -u http://localhost:8080/cbioportal -v -html /scratch/pmancini/cbioportal/reports/myReportlunglistes.html
+```
 
-### Fusion des .maf
+### Récupération du raport d'importation
 
-Le script entrypoint.py de vcf2maf possède une option --merge-maf qu'il faut utiliser pour l'importation
-dans cBioportal.
 
+Utiliser le script python:
 
-## build_study_data.py
 
-Pour importer les fichiers .maf dans cBioportal il faut les organiser dans des dossiers spécifiques et les accompagner de fichiers de métadonnées.
+TODO: tester la commande
+```python
+python3 transfer_reports.py --reports-path {Remote reposts' dir}
+```
 
-Le script build_study_data.py construit l'arborescence de fichiers d'importation.
 
-Prendre en entrée le chemin du dossier contenant les fichiers .vcf à importer dans cBioportal.
 
 
 
-## Commande d'importation et rapport d'importation
+### Suppression de study dans cBioportal
 
-
-Une fois les l'arborescence construite, on peut suivre les instructions de la documentation officielle:
-
-http://cbioportal.readthedocs.io/en/latest/Importer-Tool.html
-
diff --git a/transfer_reports.py b/transfer_reports.py
--- a/transfer_reports.py
+++ b/transfer_reports.py
@@ -71,7 +71,6 @@
     local_cmd_list = ['rsync -av --include=\'*.html\' --remove-source-files {}:{}/ {}'.format(k2so_login,
         reports_remote_path, 'reports')]
 
-
     local_cmd = ''
     for cmd in local_cmd_list:
         local_cmd = local_cmd + '\n' + cmd
diff --git a/transfer_study.py b/transfer_study.py
--- a/transfer_study.py
+++ b/transfer_study.py
@@ -56,22 +56,18 @@
     study_path_masternode = '/scratch/pmancini/cbioportal'
     study_path_virtualnode = '/data/dockerbuilds/cbioportal/studies/'
 
+    study_path_local = args.study_path
+
     local_wd = path.join(*path.normpath(args.study_path).split('/')[:-1])
 
     # Copie du dossier study sur k2so
     print('Transfert du dossier {} sur {}'.format(Bcolors.OKBLUE + study_name + Bcolors.ENDC,
         Bcolors.OKBLUE + k2so_login + Bcolors.ENDC))
     # Backup des study localement
-    local_cmd_list = ['scp -r {} {}:{}'.format(study_name, k2so_login, path.join(study_path_masternode, study_name)),
-        'mv -f {name} studies_backup/{name}{time}'.format(name=study_name,
-            time=time.strftime('-%H:%M-%d-%m', time.localtime()))
-    ]
+    local_cmd ='scp -r {} {}:{}'.format(study_path_local, 
+        k2so_login, path.join(study_path_masternode, study_name))
 
-    local_cmd = ''
-    for cmd in local_cmd_list:
-        local_cmd = local_cmd + '\n' + cmd
-
-    subprocess.run(local_cmd, shell=True, cwd=local_wd)
+    subprocess.run(local_cmd, shell=True)
 
     # Backup de la précédente study si elle a le même nom
     bash_cmd = 'cd {virtual} \n mv -f {name} studies_backup/{name}{time}'.format(name=study_name,
